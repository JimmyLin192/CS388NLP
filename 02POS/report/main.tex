%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  THIS TEX FILE IS TO GENERATE PDF FILE FOR 
%%% 
%%%  COPYRIGHT (C) JIMMY LIN, 2013, UT AUSTIN
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[11pt,a4paper]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  PACKAGES USED IN THIS TEX SOURCE FILE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{geometry,amsthm,amsmath,graphicx,fancyheadings,amsfonts}
\usepackage{amssymb}
\usepackage{tocloft}
\usepackage{enumitem}
\usepackage[colorlinks,
            linkcolor=blue,
            anchorcolor=red,
            citecolor=green
            ]{hyperref}
% for my mac
\IfFileExists{/Users/JimmyLin/.latex/UTA_CS/JS.sty}{ 
    \usepackage{/Users/JimmyLin/.latex/UTA_CS/JS}
    \usepackage{/Users/JimmyLin/.latex/UTA_CS/JSASGN}
}{} 
% for UT's linux machine
\IfFileExists{/u/jimmylin/workspace/Configs/latex/UTA_CS/JS.sty}{
    \usepackage{/u/jimmylin/.latex/UTA_CS/JS} 
    \usepackage{/u/jimmylin/.latex/UTA_CS/JSASGN}
}{} 
\DeclareMathOperator*{\median}{median}
\DeclareMathOperator*{\mean}{mean}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% MACROS CONTAINING THE FILE INFORMATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\COURSE}{CS388 Natural Language Processing}
\renewcommand{\LECTURER}{Prof. Raymond J. Mooney}
\renewcommand{\SECTION}{51360}
\renewcommand{\TASK}{Programming Assignment 02}
\renewcommand{\RELEASEDATE}{Feb. 20 2016}
\renewcommand{\DUEDATE}{Mar. 08 2016}
\renewcommand{\TIMECONSUME}{10 hours}

\setlength{\cftsecnumwidth}{6.3em}
\renewcommand{\thesection}{\arabic{section}.}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\contentsname}{List of Problems}
\newcommand{\E}[1]{\ensuremath{\mathbb{E}[#1]}}
\renewcommand{\Pr}[1]{\ensuremath{\mathbf{Pr}[#1]}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% DOCUMENTATION STARTS FROM HERE 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% TITLE PAGE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{titlepage}
    \maketitle
\end{titlepage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CONTENT PAGE: TABLEOFCONTENTS, LISTOFTABLES, LIST OF FIGURES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{center} 
%    \tableofcontents  
%    %\listoftables 
%    %\listoffigures
%\end{center}
%\newpage
\parindent 0in
\parskip 1.5ex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% GENERAL DOCUMENTATION BEGINS 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{section}{Problem Statement}

\end{section}

\begin{section}{Experiment}
    Comparisons of word perplexity between various Bigram Models
    can be found at Table \ref{wptable}.  

    \begin{table}[h] \centering
        \caption{Word Perplexity Comparisons between Various Bigram Models}
        \label{wptable}
        \begin{tabular}{|c||c|c||c|c||c|c|}
            \hline
            Datasets  & \multicolumn{2}{|c||}{atis} & \multicolumn{2}{|c||}{wsj} & 
            \multicolumn{2}{|c|}{brown} \\ \hline
            Bigram Models  & training & testing & training & testing  &training & testing  \\ \hline
  Forward & 10.59 & 24.05 & 88.89 & 275.12 & 113.36  & 310.67 \\
  Backward & 9.11 & 21.71 & 71.04 & 205.75 & 89.30 & 218.79 \\
  Bidirectional & 9.37 &  17.54 & 48.60 & 130.48 & 63.74 & 172.75 \\
            \hline
        \end{tabular}
    \end{table}

    Note that the Bidirectional Model employs even interporlation from Forward
    Model and Backward Model in the normal probability space (not log
    probability space).

    From the Table \ref{wptable}, it can be observed that Backward Model and
    Bidirectional Model reach lower word perplexity (which is better) than
    Forward Model in any training/testing set derived from three
    experimental datasets. 
    Furthermore, Bidirectional Model outperforms Forward Model in any
    scenario except the case of the training set from atis. This could be
    out of the overfitting phenomenon.

\end{section}


\begin{section}{Discussion}
How does the overall test accuracy of CRF and HMM differ (when using only tokens) and why?

How does the test accuracy for OOV items for CRF and HMM differ (when using only tokens) and why?

How does the training accuracy of HMM and CRF differ and why?

How does the run time of HMM and CRF differ and why?

How does adding orthographic features affect the accuracy (both overall and OOV) and runtime of the CRF and why?

Which features helped the most? 

\end{section}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% General Documentation ends
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
